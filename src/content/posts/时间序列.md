---
title: "时间序列"
pubDate: "2025-10-24"
modifiedDate: "2026-01-18"
---

## 术语
1. **时间分辨率（Temporal Resolution）** 是指系统能够区分或测量时间间隔的最小精度，也就是时间维度上的"精细程度"。
时间分辨率表示：
- **最小可检测的时间间隔**
- **系统在时间轴上的采样密度**
- **能够分辨两个连续事件的最短时间差**
## TimesNet [@wuTimesNetTemporal2DVariation2022]
![](https://pic.imgdd.cc/item/682ae1533c3a6234d32f857a.png)
核心架构就是这张图，首先通过快速傅里叶变换识别时间序列上的可能周期，选取前k个最大振幅对应的周期，将时间序列按周期分割后并排放在一起（最后一部分用零填补到相同长度）。再使用二维卷积在并排的多个时间序列上提取特征。
这种方式是一种多周期分析，即将混杂的时序变化解耦为具有不同周期长度的多个成分。


## iTransformer [@liuITransformerInvertedTransformers2023]
本文认为Transformer架构在时序预测上性能不佳的主要原因有，如下图所示，上方的transformer在预测时是将同一时刻的不同特征嵌入成为一个token，这使得多元变量的相关性被擦除（不是很令人信服，多个变量映射成一个token为什么不会在一个token中保留这些变量的相关信息呢，除非不同变量之间有一些固有的关系但通过将每个时间点映射成一个token使得这种变量级别的固有关系被破坏了），而且感受野过度局部化，事件之间可能不具有同步性（即一个特征在某个时间点发生的事件实则应该和另一特征在后面发生的事件具有关联，只看同一个时间点下的特征相关性未必有效，这个说法比较可靠）。以及时序维度上不应采用置换不变的注意力机制，因为序列变化和顺序紧密相关。
![](https://pic.imgdd.cc/item/682c41ca3c3a6234d3340d8d.png)
文中提到了“通用逼近定理”[@hornikApproximationCapabilitiesMultilayer1991]，实则就是讲述只要隐藏层足够大，网络足够复杂，就一定能拟合任意函数。
本文的结构如图中下半部分所示，先对整个序列做embedding嵌入（使用MLP），再使用注意力机制对得到的不同特征序列的embedding进行分析，再对特征序列使用FFN得到最终的特征最终投影为输出结果。
这样的好处是充分保留了每个特征的时序信息。而MLP在之前的许多研究中已经被证明具有捕捉时间序列中的时序特征的能力。
![](https://pic.imgdd.cc/item/682d5ab93c3a6234d335146e.png)
## TimeMixer [@wangTimeMixerDecomposableMultiscale2024]
![](https://pic.imgdd.cc/item/682d815c3c3a6234d33545df.png)
TimeMixer核心思路是充分利用时间序列不同尺度上的信息，最终通过混合预测的方式得到最终预测结果。
这里得到“不同尺度”的方式是通过下采样将序列逐步采样为更短的序列（实际上每次采样为之前的一半长度，采样方式是平均池化）。
因为时间序列包含有趋势性特征（长期特征）和季节性特征（周期特征，较短），因此利用autoformer的方式将采样出来的每个序列都分解为这两种特征，再对季节性特征进行自下而上的方法，从较细粒度的特征向上整合信息直到顶端最粗粒度的特征，这里的整合是一步步进行的，公式为
$$
\text{for } m: 1 \rightarrow M \text{ do:} \quad s_m^l = s_m^l + \text{Bottom-Up-Mixing}(s_{m-1}^l)

$$
此处Bottom-Up-Mixing为一个两层的MLP。
对趋势性特征则采取相反的方式，使用自上而下的方法整合信息，公式类似
$$
\text{for } m: (M-1) \rightarrow 0 \text{ do:} \quad t_m^l = t_m^l + \text{Top-Down-Mixing}(t_{m+1}^l)
$$
同样是两层的MLP
混合预测器即对不同尺度的特征序列都使用线性层预测一个长度为F的未来序列，再将这些预测器得到的结果混合（此处为加和）得到最终预测结果。公式为
$$
\hat{\mathbf{x}}_m = \text{Predictor}_m(\mathbf{x}_m^L), \quad m \in \{0, \cdots, M\}, \quad \hat{\mathbf{x}} = \sum_{m=0}^{M} \hat{\mathbf{x}}_m
$$
这篇文章思路清晰，模型结构简洁，易于理解，是一片很值得借鉴的文章。

## TimeMixer++ [@wangTimeMixerGeneralTime2024]
![](https://pic.imgdd.cc/item/682ec1c93c3a6234d3369573.png)
这是TimeMixer++的结构图，既然叫TimeMixer++肯定和TimeMixer有共通之处，由图中结构可以看到，对输入进行下采样并得到M个不同长度的序列的方式和TimeMixer相同，只是TimeMixer用的方式是平均池化而此处则改为了步长为2的卷积操作（感觉意义不大，可能纯粹为了模型结构不同）。
核心的MixerBlock模块，不再是直接将各个序列直接分解为season和trend两个部分，而是借鉴了timesnet的思路，将各个序列按照不同周期分割并纵向拼成二维时间序列图，这里周期的计算方式也和timesnet一样使用FFT（快速傅里叶变换）找到振幅最大的top-k个频率并计算对应的周期即为选取的周期。得到这样的二维时间图后，没有像timesnet直接使用二维卷积，而是先使用了双轴注意力机制，双轴注意力即指在得到的二维时间图的行方向和列方向分别使用注意力机制得到不同的特征序列，按照图片中的序列排布方式，对列方向使用注意力机制即为在分割出的每个周期序列内部使用注意力机制，因此得到的是season性质的特征具有一定的周期性，而行方向使用注意力机制则是对分割出的每个周期序列的同一个相位处使用注意力机制，对每一行相当于用这一点的数据来代表该周期的数据进而得到一个整体的趋势变化。这样分别得到了一系列的季节性特征和趋势特征。
此时对每个周期都对应M+1张不同的季节性时序图像和趋势性时序图像。对季节性时序图像和趋势性时序图像，采用TimeMixer中的思路进行混合，对季节性从细粒度到粗粒度混合，趋势性则从粗粒度到细粒度混合，但这里混合不再使用简单的两层MLP而是使用窗口为2x2的二维卷积，从细到粗是正常的卷积（下采样），从粗到细则是反卷积（上采样，增大尺寸）。最终不同分辨率图像的混合是加权求和，权重为对应的频率振幅的相对大小（做归一化处理）。
这篇文章很多词汇让人琢磨不透，但只要记住文中的不同分辨率（resolution）是指不同周期（不同频率）的序列，不同尺度（scale）指仿照TimeMixer中通过下采样得到的不同长度的序列，就能明白本文的核心内容。非常成功的将TimesNet和TimeMixer二者混合在一起。

## PatchTST [@20243116790377]

也是一个经典之作，经常被拿来当作baseline比较。
![](https://pic.imgdd.cc/item/683eb1c33c3a6234d3417f2c.png)
结构如图，用于baseline是因为本文提出的结构非常简单明了，且适用性广泛，题目非常直观表达出了文章的核心思想，一个时间序列相当于64个单词，在语言当中我们会把字母组合成单词，把单词作为独立的token进行处理，在时间序列中也是如此，直接将每个时间点的数据都拿来作为输入相当于在文本中将字母作为输入，应该模仿单词的处理方式通过将时间序列数据分块分割（Patch）来分别作为一个token输入。对于多变量的时间序列，文中将每个变量的时间序列作为单独的通道处理。
将分块作为token输入时加上位置嵌入模仿标准的Transformer输入，再将输入送入Transformer编码器中，对于有监督学习任务将输出展平到一维后使用线性头输出预测序列，对于自监督则使用掩码学习，遮蔽掉部分分块后的数据让模型预测复原这些遮蔽部分。注意在有监督学习任务中对不同通道的数据使用共享的Transformer权重，但是不同的前向输出部分。最终的输出要将所有patch对应的特征全部连接在一起并展平，再通过线性层映射到最终结果。相当于利用所有patch的信息来做最终预测。
本文的两大核心贡献，一是Patch，进行Patch之后，一方面聚合了局部的语义信息，另一方面相比于之前的将每个时间点都视为一个token使用Transformer分析的模型，将每个Patch视为一个token可以大大减少运算量。
Patch是怎么想到的呢，从文中可以大概了解，作者提出即使使用相同的输入长度，更长的回看时间窗口可以增进模型的预测性能，文中使用了每隔四个时间点采样的方式，在回看窗口为380的序列上采样得到96长度的输入序列（和一般的使用最近96个时间点作为输入的长度相同），得到了比使用最近96个时间点的数据作为输入更好的预测性能。因为时间序列含有很多冗余信息，过去有研究表明即使忽视了部分时间点的数据，模型也能获得足够的信息用于预测。通过Patch的方式可以从更长时间的回看窗口中学习特征，Patch相当于一种过滤冗余信息的方式，同时还大大减少了从更长回看窗口学习时的运算量。
二是通道独立，文中认为通道独立有三个优势：
1. 适应性，通道独立使得每个通道有自己的注意力模式，从而更加适配不同特征的不同变化特性。
2. 通道混合模型可能需要更多训练数据才能达到通道独立模型的性能。
3. 通道独立模型在训练期间更不容易过拟合 (overfit)，对噪声更具鲁棒性。如果一个或多个序列中的噪声占主导地位，那么在混合通道时，这种噪声将在嵌入空间中被投射到其他序列上。通道独立可以通过将噪声仅保留在这些含噪通道中来缓解此问题。
文中也提到，可以使用图神经网络等方法来学习跨通道关系。

## Moment [@goswamiMOMENTFamilyOpen2024]
看了许多的时间序列的文章自然会联想到LLM，对时间序列是否有可能像LLM一样通过弱监督预训练得到一个大模型，再通过简单的变换输出头即可适配各种下游任务呢，果然你能想到别人也能想到而且都做出来了，这篇文章就是针对时间序列的预训练模型。
本文主要贡献一是给出了一个公开的大规模时序数据库。二是基于这个大规模数据库尝试了多数据集预训练。三则是提出了一系列评估基准。
具体训练的部分，主要借鉴了PatchTST的思路，将时间片分割成一个个patch，用注意力机制将每个patch变换成D维特征。再通过mask建模的思路，让模型学习预测mask的部分。
![](https://pic.imgdd.cc/item/68304ab73c3a6234d3383d81.png)

与PatchTST对比可以发现模型结构基本没有变化，最大的区别是这个模型是在公开大规模时序数据库上训练得到的。但在最终结果比较上，虽然优于TimesNet等几年前的模型，但在很多任务上都弱于监督学习得到的PatchTST。

## OLinear  
两个主要贡献：
1. 不同于常用的 TF 范式，提出了 OrthoTrans——一种数据自适应变换方案，该方案利用时间皮尔逊相关矩阵特征值分解得到的正交矩阵。作为即插即用模块，它能持续提升现有预测模型的性能。
2. 为优化表示学习，提出 NormLin 层，采用行归一化权重矩阵来捕捉多元相关性。值得注意的是，作为即插即用模块，NormLin 既能提升基于 Transformer 预测器的精度与效率，也能良好适配解码器架构和大规模时间序列模型。
其中第一个主要贡献里提到的TF范式，即temporal forecast范式，指的是直接处理原始的时间序列数据，将原始时间序列编码为潜在表征再进行后续处理，文中提到该范式难以充分挖掘序列内部纠缠依赖关系，因此需要通过一些信号领域的工具，将原始时间序列转化成一些**去相关特征（此处翻译为解耦或许更合适）序列**（**decorrelated feature sequence**，意思是原始序列中的数据可能是有多种相关性融合在一起的序列，如通过傅里叶变换将序列转化成多个正弦波，从而将这种相关性分离开），这里的去相关作者提到的相关是指时间先后具有相关性，即时刻t+1的数据受到时刻t的影响，而通过对子序列进行相关系数分析后进行正交分解，则可以将原来不同时刻具有相关性的数据变成时刻之间特征独立的数据。
作者认为傅里叶变换或者小波变换依赖与数据集无关的基函数，不能充分利用数据特有的时序关联信息。因此需要一种可以利用数据特有的时序信息的数据变换方案，将原始时间序列数据转换成一些分离的特征序列。即文中的OrthoTrans。
第二个贡献的前提是注意到自注意力机制中，注意力值均为正且行L1范数固定为1，即每一个位置对其他各个位置的注意力的和为1且均为正，这是因为注意力的含义指和其他各个位置相关的概率，概率和当然为1。如有n个位置，则第i行即第i个位置和其他位置相关的概率。这个概率是通过Q\*K^T来计算的。

值得关注的点
1. 对原始输入和输出进行变换的正交矩阵是通过一部分数据（作者使用的是训练数据，同时文章后面有验证证实数据量的多少对得到的正交矩阵最终的效果影响不大）预先计算出来的，计算出来之后在后续的整个训练和推理过程中都直接使用。
2. 本文的通过计算皮尔逊相关系数计算正交矩阵的过程可以理解为对一个多特征的时间序列样本按顺序取多个相同长度的子数组，这些子数组相当于取的子样本，再通过计算相关系数发掘这些子样本之间的相关性，以此得到不同时刻差之间的相关性。对每个特征都进行这样的计算最终取平均就是最终的皮尔逊相关矩阵，但这仅是一个样本的计算过程。
3. 对输入先经过RevIN层进行实例归一化来缓解非平稳性，RevIN层见[[#RevIN [@kimReversibleInstanceNormalization2021]]，后面提到的乘以一个1XN的矩阵进行维度扩展来学习更多特征其实源自NLP中的embedding，此处的作用就是对输入的时间序列进行embedding。


## RevIN [@kimReversibleInstanceNormalization2021]

RevIN原理上非常简洁，是一种解决数据分布偏移问题的方案，其核心在于构建归一化-反归一化对称结构，对输入进行归一化，对输出进行反归一化。这里的归一化即类似常用的layer normalization即层归一化，公式如下
$$ \hat{x}_{kt}^{(i)} = \gamma_k\left(\frac{x_{kt}^{(i)} - \mathbb{E}_t[x_{kt}^{(i)}]}{\sqrt{\mathrm{Var}[x_{kt}^{(i)}] + \epsilon}}\right) + \beta_k $$
其中$\gamma_k$和$\beta_k$为可学习的仿设参数向量，实际使用中这两个参数既可以在所有特征上保持一致，也可以在每个特征上独立。
反归一化过程则是使用相同的参数将数据反归一化将一些非平稳特性还原到模型输出当中，公式如下
$$ \hat{y}_{kt}^{(i)} = \sqrt{\mathrm{Var}[x_{kt}^{(i)}] + \epsilon}\left(\frac{\hat{y}_{kt}^{(i)} - \beta_k}{\gamma_k}\right) + \mathbb{E}_t[\hat{x}_{kt}^{(i)}] $$
文中提到，最好将RevIN添加到网络中近乎对称的位置，如果是编码器，解码器结构则对称的位置很容易寻找即二者中比较对称的层级即可，但时序预测模型很多并没有清晰的编码器-解码器结构，因此直接将RevIN应用于模型的输入层和输出层即可视为一种对称结构。

## DLinear [@zengAreTransformersEffective2023]

本文是著名的比较Transformer和线性模型并对Transformer在时序问题建模中的有效性提出质疑的文章。
文中提出了一个很简单的线性模型，通过简单的线性映射从步长为S的序列直接映射到步长为P的目标序列，中间经过一些AvgPool等平均池化的部分。最终得到了性能很好的模型。

## xPatch [@stitsyukXPatchDualstreamTime2025]
这篇文章的主要贡献在于三点，依次解读
1. 将之前始于Autoformer的分离趋势项和季节项时，获得趋势项使用的简单移动平均改为移动指数平均，从而获得更符合数据特征的趋势项。
![](https://pic1.imgdb.cn/item/6894c42a58cb8da5c80ff8fd.png)
2. 使用了双流模型，两个流分别分析数据的趋势项和季节项，对趋势项使用简单的线性模型，特意去除了激活函数以保留线性特征。季节项则使用了深度可分离卷积神经网络，目标是学习季节项中的非线性特征。其实这里采用的深度可分离卷积神经网络的思想来源是这篇文章[[#ModernTCN]]，其实现方式和ModernTCN中基本一模一样。

## ModernTCN ([@ICLR2024_86b1437c])
可参考知乎上一个博主的论文解读[ModernTCN解读](https://zhuanlan.zhihu.com/p/668946041)。
主要动机是发现在时间序列领域，最近大部分模型都是基于Transformer或者MLP的，基于CNN的模型没有这些的效果好，但是在计算机视觉领域，很多现代CNN的性能都超过了vision Transformer，于是想探究卷积是不是可以在时间序列领域获得更好的性能，为此有两点可以改进的地方，首先现代CNN都有很大的卷积核来提升感受野，再一个就是充分利用卷积来捕获跨变量依赖性。也正是质疑PatchTST中的变量独立的做法。
首先，在embedding的过程中，cv一般是直接混合RGB变量。而在时间序列中，这种方式不适用，因为一个简单的embedding显然无法充分建模变量间关系。如果在embedding时就已经把变量混合了起来，那后续对变量间的建模则是混乱的。因此，作者提出了变量无关embedding，也是用了分patch的方法，对每个变量独立分patch进行embedding。这里说的分patch和PatchTST里的分patch是完全不同的思路，PatchTST里分patch就是直接把整个序列切成不同的小块通过MLP来映射，这里则是通过卷积对每个小块进行不同方式的“滤波”。每种“滤波”方式都能得到一个特征值，d_model种滤波方式就能得到d_model个值，这就得到了一个d_model的向量。具体在代码实现上，作者是采用有stride的卷积，在这里先给出了代码实现，先介绍下代码相关的注释：
```python3
# B：batch size
# M：多变量序列的变量数
# L：过去序列的长度
# T: 预测序列的长度
# N: 分Patch后Patch的个数
# D：每个变量的通道数
# P：kernel size of embedding layer
# S：stride of embedding layer
```

Embedding模块先将一个特征的输入unsqueeze，新增一个通道维，然后pad之后（方便整除）应用有stride的1D卷积来进行patch embedding，如下：

```python
class Embedding(nn.Module):
    def __init__(self, P=8, S=4, D=2048):
        super(Embedding, self).__init__()
        self.P = P
        self.S = S
        self.conv = nn.Conv1d(
            in_channels=1, 
            out_channels=D, 
            kernel_size=P, 
            stride=S
            )

    def forward(self, x):
        # x: [B, M, L]
        B = x.shape[0]
        x = x.unsqueeze(2)  # [B, M, L] -> [B, M, 1, L]
        x = rearrange(x, 'b m r l -> (b m) r l')  # [B, M, 1, L] -> [B*M, 1, L]
        x_pad = F.pad(
            x,
            pad=(0, self.P-self.S),
            mode='replicate'
            )  # [B*M, 1, L] -> [B*M, 1, L+P-S]
        
        x_emb = self.conv(x_pad)  # [B*M, 1, L+P-S] -> [B*M, D, N]
        x_emb = rearrange(x_emb, '(b m) d n -> b m d n', b=B)  # [B*M, D, N] -> [B, M, D, N]

        return x_emb  # x_emb: [B, M, D, N]
```
其实这一步操作和一个从patch_len到D的全连接层从数学上没有区别，但是卷积经过一些工程实现上的优化，在实际使用过程中可能会更快一些。
得到嵌入后，经过堆叠的ModernTCN block处理就可以得到最终结果。此处每个ModernTCN block的设计为![](https://pic1.imgdb.cn/item/68d94f31c5157e1a88411198.png)
DWConv是对每个变量沿时间方向上卷积，即对得到的N个D维嵌入，在N的方向上进行卷积，这里如果输入序列长度为96的话，得到的N是24，比预设的大卷积核51还要小，因此实际操作中使用padding='same'在左右两边填充0，使得最终经过卷积后得到的还是24个值，这里通过一个很大的卷积核使得前面的值可以看到序列前面的信息，中间的可以看到整个序列，后面的可以看到后面一些的信息。再通过第一个ConvFFN1融合每个嵌入内部的信息，这里ConvFFN1是一个分组卷积，意义是对每个嵌入向量内部相邻信息做融合，注意此处的kernerl_size是1，所以本质上和一个FFN没什么区别，只是用卷积的形式实现。ConvFFN2则是融合同一个时间步纵向的不同变量的同一个patch对应的嵌入的信息，这里相当于对嵌入的每一维在变量方向上连接起来再通过一个FFN。这样分别显式建模了时间方向的信息，嵌入内部的信息和不同变量的信息。作者做了消融实验，证明无论删掉ConvFFN1还是ConvFFN2都会导致性能下降。
此处ConvFFN1相当于每个变量独立参数的FFN，而ConvFFN2相当与每个嵌入在变量方向上独立参数的FFN。这样觉得好像参数量很大，但最终看到ModernTCN的参数量在2048M，竟然还算是参数量比较少的模型，以前我设计的模型有些参数量甚至不到1M，看来以后可以扩大模型规模。
这篇文章给我们一个提示在于建模过程中要对嵌入的各个维度进行单独建模，要深入理解嵌入这个概念，嵌入相当于将信息都映射到一个高维空间中，那么这个空间中的各个维度可能自身都有一定的含义，因此可以对每个维度独立建模，同时也可以对不同维度的信息组合建模。组合方式有很多，卷积就是其中之一。而其他模型是在这个思想的基础上再加入一些宏观上可以建模的信息，如xPatch中显式的建模趋势成分，但季节成分的建模思路还是和本篇文章相同。
这里的模型细节是在长时预测任务中，设定的D = 64，前馈网络（FFN）的比率 r = 8（即中间隐藏层比初始维度的比率）。卷积核大小设置为大尺寸 = 51 和小尺寸 = 5。在补丁化嵌入（patchify embedding）过程中，补丁（patch）大小和步幅（stride）分别设置为 P = 8, S = 4。对于较大的数据集（ETTm1 和 ETTm2），我们堆叠 3 个 ModernTCN 模块以增强模型的表示能力。对于小数据集（ETTh1、ETTh2、Exchange 和 ILI），我们建议使用较小的 FFN 比率 r = 1，以减轻可能的过拟合，并提高内存效率。
经过超参数搜索（不同输入序列长度）后的最佳性能
![](https://pic1.imgdb.cn/item/68db3d73c5157e1a88475d33.png)
## DUET [@qiuDUETDualClustering2025]
本文提出了一种灵活建模同一通道内时序特征和不同通道之间的关系的方法，对一个通道的时序特征，采用一个模式提取器集群，即有多个模式提取器，都是基于线性模型。
这里选择提取器的过程类似于一种MoE过程，此处假设所有时间序列都遵循一个潜在的正态分布，则用两个编码器分别建模这个潜分布的均值和方差，采用重参数化技巧得到每个时间序列对应的最终潜变量，这里提到Noisy Gating就是在门控中加入少许随机噪音，正好可以对应对高斯分布进行重参数化的随机项。得到潜变量后，这个潜变量的维度为M，即对应M个候选模式提取器，取topk个概率并用softmax计算概率即得到选取的k个模式提取器分别对应的门控概率。随后将原始时间序列分解为季节和趋势项，并分别用两个线性模型建模两项并加和得到D维嵌入，对M个候选模式提取器提取出来的嵌入通过刚才的门控概率加和得到最终的D维时序特征。
![](https://pic1.imgdb.cn/item/68da45e6c5157e1a884500f8.png)
注意这里没有采用很多人使用的Patch的方法来提取时序特征，而是通过直接对整个时间序列进行不同模式的特征提取并加和得到最终特征。这种方法的一个潜在问题是如果输入时间序列特别长，则即使是线性变换也会有很大的参数量。
对通道之间的信息，整体思路上还是对不同通道通道之间的整体信息进行融合，只是不再是全部融合，而是通过“软聚类”来融合，此处聚类的方式是将时序数据通过实数快速傅里叶变换到频域，再通过马氏距离来衡量不同通道之间的距离以此来发掘相关性，马氏距离可以理解为对原始空间进行主成分分析并进行空间转换，特征向量作为转换后的正交坐标轴，随后再对原始数据进行标准化后再在这个空间中使用欧式距离来横向向量之间的距离，这一做法的好处是转换后的空间消除了坐标之间的相关性。
## HDMixer [@huangHDMixerHierarchicalDependency2024]
该文章的核心思想和我最近想到的对Patch类模型的可能改进思路相似，主要涉及到两个问题
1. 之前的Patch模型中Patch都是定长的，定长的Patch对信息的捕获能力有限，尤其是位于Patch边界的关键信息可能会被两个Patch分割从而丢失，论文中的描述为

> 这些⽅法（Nie 等⼈，2023，[[#PatchTST [@20243116790377]]]）采⽤固定⻓度的⽚段， 并直观地假设固定划分时间序列的⽅式具有普适性。然⽽， 这种固定⽚段的划分方法在将时间序列划分为⼦序列时缺乏灵活性，导致了两个问题：（1）⽚段边界信息丢失。⼦序列丢失了关键的边界信息，⽆法形成具有⾼信息量的局部语义表示。如图 1 所示，峰值信息因固定⻓度⽚段⽽丢失。（2）序列语义不连贯。这导致整个序列的语义处理不⼀致。如图 1 所示，峰值 信息在不同⽚段间不⼀致地出现。因此，这种固定⽚段⽅法 可能会损害序列的语义信息，导致性能下降。
![](https://pic1.imgdb.cn/item/68c187f158cb8da5c898eb19.png)
2. 很多模型设计时只考虑了每个通道内序列信息的提取和处理，没有考虑通道间的信息相关性。论文中的描述为
> ⼤多数现有⽅法（Nie 等⼈，2023；Zhang 和 Yan，2023；Zhang 等⼈，2022a）侧重于通过基于⽚段的⽅法来丰富多元时间序列（MTS）中的局部语义，主要强调捕获⻓期交互。然⽽，它们往往忽略了另外两种关键的信息交换形式：(a) 短期交互和(b) 跨变量交互。⼀⽅⾯，捕捉短期交互有助于相邻时间步之间的频繁信息交换，从⽽帮助识别局部模式和瞬态事件。另⼀⽅⾯，提取跨变量交互可以揭示隐藏在数据变化中的潜在因果关系。尽管少数跨变量技术（Zhang and Yan 2023）试图显式捕捉这些交互，但它们通常涉及较⾼的计算复杂度。此外，当前研究也忽略了分块内部的短期依赖关系。整合所有三个维度的交互有望增强多元时间序列预测模型的表示能⼒。

此处对于通道相关性，考虑的是同一段时间的不同通道之间的相关性。

HDMixer的主要设计包括Length-Extendable Patcher（LEP），长度可扩展分块和完全由MLP构建的层次化依赖探索器。
LEP可以⾃适应地扩展补丁⻓度，并采⽤双线性插值在每个补丁内均匀采样固定数量 D 个时间步，从⽽形成更完整的语义补丁划分策略。LEP和传统的固定长度Patch的区别在于LEP在之前固定长度Patch可知Patch的中心位置的基础上，将中心位置的偏移量，Patch的左侧扩展长度，右侧扩展长度均设置为可学习的变量，由此新得到的左侧边界下标和右侧边界下标分别为

## CARD [@ICLR2024_2f4d6f8e]
本文对输入同样采用Patch的方法，只是对Patch后通过MLP得到的嵌入增加了一个额外令牌T0，同样为D维，类似一种静态协变量编码器，这个方法也是参考了其他论文中的思路，还有位置嵌入。论文有些笔误，比如线性投影在公式里的对应说成是MLP，MLP应该是线性投影和非线性激活函数的组合。
对通道内的信息，除了标准的对嵌入之间做注意力机制外，还引入了一种新的对嵌入内做注意力的方法，这个方法就是将维度变换一下，假设原始嵌入序列的长度为N，嵌入维度为D，则标准注意力是在N这个序列上执行，而嵌入内注意力则是将D视为序列长度，将N作为一个嵌入，在D这个序列上执行。这种在嵌入内执行信息融合的思路和ModernTCN的通道间信息融合的思路相近。
![](https://pic1.imgdb.cn/item/68db4c4fc5157e1a8847ead6.png)
对通道间的信息，由于像Traffic这样的数据集维度特别高，如果直接使用全注意力比建模通道内的计算成本高得多，因此使用了一种“摘要化”令牌的方式，这里对每个时间点不同通道之间的嵌入，共有C x D个，先将每个嵌入从D投影到r（r<<C)，再经过softmax归一化后转置得到r x C的投影向量，再将r x C和原始的C x D嵌入相乘得到r x D个嵌入，因为r << C，所以这样相当于将每个时间点的不同通道的信息摘要化为r个，最后将通道内的信息和通道间的信息相混合。最终经过MLP输出得到最终结果。
![](https://pic1.imgdb.cn/item/68db4c15c5157e1a8847e81b.png)
这篇文章感觉是在设计上下的功夫比较多。也是一个baseline。但感觉也是设计过于复杂，尤其是注意力的各种不同处理方式。像ModernTCN最大的好处就是设计非常简约。
## CCM [@chenSimilaritySuperiorityChannel2024]

CCM是一篇比较精简的文章，核心思想是通道之间存在关联性，则可以先将通道分组，而之前很多模型对每个通道单独使用一个FFN，本文指出可以通过对通道全局嵌入投影得到二维嵌入后通过最近邻方式来分组，其实整体思想某些地方和[[时间序列#DUET]]很像，
## PS Loss [@kudratPatchwiseStructuralLoss2025]

![](https://pic2.imgdd.cc/item/68a45e52e65701530c42d66f.png)
本文主要说明了一种比较新的时序预测中使用的Loss的设计方法，问题来自于简单的MSE损失不能很好的反应时序数据的特征，如下图，图中的三个时间序列具有相同的均方误差，但显然具有不同的不匹配的特性。
![](https://pic2.imgdd.cc/item/68a45eade65701530c42d67d.png)

## MTGNN [@wuConnectingDotsMultivariate2020]

将图神经网络用于多元时间序列的经典之作，截止目前有2000多的引用量。
文中提到了图神经网络的三个特性：排列不变性、局部连接性和组合性（permutation-invariance, local connectivity, and compositionality）。

## Hi-Patch
这篇文章的目标是解决具有不规则时间间隔的多变量时间序列的预测和分类问题，但思想也可以用于规则的多变量时间序列中。
本文使用了一种堆叠的图神经网络，


## FTMixer [@liFTMixerFrequencyTime2025]
本文的核心是充分利用频域信息，将时域信息和频域信息进行结合。
对于频域使用离散余弦变换将时域数据转换至频域，仅处理实数部分，可以将原始长度为T的时序数据转换为长度为T的频域数据。
![](https://pic1.imgdb.cn/item/68db74bdc5157e1a88495755.png)
对频域信息的处理，使用了两个模块，一个是FCC，一个是WFC。FCC用来融合序列之间的信息，WFC用来融合序列内的信息。
对FCC，首先通过DCT（离散余弦变换）将时序数据转换成频域数据，随后将频域数据通过线性层映射到d_model的嵌入，再在d_model的各个维度上通过跨通道的1x1卷积融合不同通道序列之间的信息，再通过线性投影投射回序列原本长度再通过iDCT转换回时域。这一模块的目的是提取不同序列之间的整体关联特征。
对WFC，则着重提取每个序列内的局部特征，先对每个序列做patch分块，这里为了捕获不同尺度的特征将patch分块按照不同尺度进行分块，对每个尺度的分块在块内做DCT映射到频域后，对不同patch的相同维度进行卷积以捕获patch之间的信息，最后通过iDCT转换回时域。这里使用了不同尺度的patch，每个尺度的patch最终都能得到一个d_model的嵌入，最终将统一序列所有尺度得到的嵌入全部拼接后通过PatchTST的方式进行信息融合后通过线性层映射回pred_len长度。
将两个模块最终得到的序列相加再使用一个MLP映射得到最终预测结果。
最终的损失函数，对时域预测结果使用MSE计算损失，增加了一个频域损失，对转换成频域后的损失使用MAE计算损失，将二者加和作为最终损失。
最终结果![](https://pic1.imgdb.cn/item/68db8168c5157e1a884a0475.png)相对于PatchTST在各个数据集上其实都只有微弱提升，这里PatchTST的真实效果数据上有些偏差。
## UniTST [@liuUniTSTEffectivelyModeling2024]
相当简单的一篇文章，如果看过PatchTST的话对这篇文章的改进一眼就能看懂，其中有一些部分的思路属于已经想过了，但是还没有想到他这一步，比如直接在整个输入的所有嵌入上直接做注意力来跨变量跨时间的动态建模不同Patch之间的关联，这个我想到了，但是这个思路显而易见的问题是当变量数特别多，Patch就会特别多，比如100个变量每个变量12个Patch就是1200个Patch，而直接执行全注意力的计算复杂度是$1200^2$级别的。假设变量数为N，序列分割的Patch数量为P，直接计算的复杂度为$(NP)^2$，另一个问题是这样显然会带来很多噪声，因为softmax注意力是归一化的，很多无关的项的权重都不会为，即使一个无关项权重很小，加在一起就会很大。但是我的思想偏离到了怎么去通过稀疏注意力的方式来解决这个问题，稀疏注意力可以解决噪声问题，但解决不了计算复杂度的问题，这篇文章则通过一种方式解决了计算复杂度的问题。
文中提到的建模不同变量，不同时间点的依赖的问题可以通过设置几个可学习代理，让可学习代理先和所有嵌入进行交叉注意力以获取不同的依赖关系，整合不同依赖关系中的信息，再让所有嵌入通过交叉注意力去关注所有可学习代理中的信息，这样就实现了间接的关注不同变量，不同时间点的Patch。
最终结果如下，输入序列长度限制为96。
![](https://pic1.imgdb.cn/item/68dde2abc5157e1a884e550e.png)
说实话，我对这篇文章的思路不是很认可，有几个原因，一个是在ETT这种变量间相关性很低的数据集上，这个模型性能相对PatchTST也能提高，有点奇怪，且现在没有代码无法直接复现。根据我自己尝试复现的结果，在原始的类似PatchTST的模型的基础上，加入文中说的可学习代理，让可学习代理先收集所有嵌入的信息，再让所有嵌入做交叉注意力关注这个可学习代理，最终在ETTm1数据集上训练得到的结果明显不如只在每个通道单独做自注意力后在每个通道直接进行预测的效果好，96和192预测步长情况下MSE都降低了约0.02，说明这种做法只引入了噪声。因此文中如何得到这个结果存疑。而在ECL这种通道间相关性比较强的数据集上，通过引入可学习代理最终得到的MSE在720预测步长上相比原始同通道获得了好得多的性能，其他预测步长也有一定提高，但提高程度不大。
第二个则是每个Patch关注的Patch应该是比较复杂的依赖，这种通过中间代理间接建模依赖的方式真的能让Patch关注到想关注的Patch吗。
## CMoS [@siCMoSRethinkingTime2025]
本文也应用了类似MoE的思想，思路清晰易懂，本文的亮点在于模型极为轻量和简洁，但仍然取得了非常优秀的预测效果。
本文首先引出，同一个序列虽然数据会随时间发生变化，但只要相对位置一致，两个滑动窗口位置处的依赖关系通常保持稳定，这里有点类似自相关的分析方法，考虑时间n和时间n+t位置处的变化趋势是否一致，如果一致的话一旦n发生变化n+t应该也会随着变化，这样n和n+t具有很强的自相关性。后续的周期注入部分，作者正是使用自相关函数来计算主导周期的。
那么我们只需要将原始序列分块，将待预测的序列也先分块，直接尝试建立块和块之间的关系，作者在这里只假定块和块之间有线性关系，则每个待预测的块可以视为历史序列块的线性组合加一个偏置项，偏置项可以用于拟合基本的趋势信息，这样这个线性组合的权重可以视为一个相关性向量，所有通道组合在一起可以视为相关性矩阵。
$$\mathbf{x}_{t+i} = \sum_{j=0}^{\frac{L}{S}} \theta_{ij} \mathbf{x}_{t-j} + \mathbf{b}_{i}$$

接下来的问题就是对每个通道如何组合相关矩阵，这里需要给相关矩阵分配权重，正常来说具有相似时间结构的通道应当有相似的权重组合。但实际因为噪音的存在，即使相似的时间结构可能在很多细微的地方都会有不一样的地方，为了过滤这种噪音，就可以使用卷积对原始序列进行滤波操作，从而对每个序列得到一个去噪后的更精简的序列，对去噪后的序列（可视为一种嵌入）直接使用线性映射映射成对相关矩阵的权重。
最终对要预测的目标块，使用相关矩阵从历史输入块通过相关性组合得到目标块，将通过所有相关矩阵得到的目标块根据相关矩阵的权重做加权和得到最终对目标块的预测结果。
最后一个则是偏技巧一些，即对于一些具有明显周期性的数据集，可以通过显式的权重编辑将先验周期性注入进去，这里先验周期的计算是通过自相关函数计算的，得到先验周期后，对这个权重矩阵，间隔周期的两部分的权重直接设置为相同的值，其余位置置为0。
该模型参数量很小，计算很快，而且可解释性非常强，如下是在Weather数据集上学到的空间相关性矩阵
![](https://pic1.imgdb.cn/item/68de2b5cc5157e1a884ea7a7.png)
Mapping 2。在块大小为 4 的设置下，Mapping 2 中的权重在末端呈现出非常明显的对角条纹模式，其中该条纹上的每个权重 θi,j 大致满足条件 180−i+j=36 。考虑到天气数据集每十分钟采样一次（每天 6×24/4=36 个数据块），这一条纹表明预测块高度依赖于一天前同一块的历史数据。换言之，映射 2 主要建模了预测值与其前一天观测值之间的短期依赖关系。
相比之下，Mapping 3 中较大的权重几乎完全集中在矩阵末端。这表明该映射建模的是极短期依赖关系，预测时高度依赖过去一小时甚至最近几分钟的观测数据。对于长期趋势难以预测但短期趋势相对稳定的时间序列而言，这是一种更有效的预测策略。
另一方面，Mapping 4 在矩阵起始处呈现出若干明显的对角条纹，这表明特定数据块的预测更依赖于较早观察到的其他数据块。因此，Mapping 4 建模的是长期依赖关系，这在具有显著且稳定周期性特征的时间序列中往往更为突出。
Mapping 1 中的权重分布相对均匀，未显现出极强或特定的依赖性。我们推测模型利用Mapping 1 来捕捉其他映射所忽略的细粒度依赖关系，即残差依赖。
![](https://pic1.imgdb.cn/item/68de2be8c5157e1a884eab2a.png)
通道 1 呈现缓慢且不可预测的趋势变化，促使模型仅使用Mapping 3 来捕捉极短期依赖关系。通道 3 同样表现出某些缓慢趋势，但每隔一天会出现峰值，且峰值形态与邻近峰值更为相似。因此，模型主要结合Mapping 2 和Mapping 3 共同建模极短期与跨日依赖关系。Mapping 4 展现出更明显的周期性特征，使得模型额外利用映射 4 中捕捉的长期依赖来提升预测性能与鲁棒性。
同时通过消融实验得到，对包含大量通道的数据，将空间相关矩阵数量置为4-8之间是不错的选择。
查看仓库代码，该模型的实现非常简单，但有一些问题要看代码得到更深入的理解。
![](https://pic1.imgdb.cn/item/68de306fc5157e1a884eb6e1.png)
首先这里设定的相关“矩阵”，是一个通道的输入分块到输出分块的线性映射，这意味着所有通道通过相关矩阵得到最终结果都是只针对单一通道的，即没有进行不同通道之间的信息混合。当然这里的相关矩阵是在所有通道上通过训练最终得到的，因此从某种角度可以认为记住了这个数据集的整体性的分块相关性（通道无关），最终组合这些相关性就可以得到在任意通道上最佳的预测方式，这里其实是对DLinear这种直接通过过去序列映射到未来序列的扩展，一是将时间点直接映射改为块对块的分块映射，这样可以显著降低噪音，这点之前在看到PatchTST时我也想到了，即除了对输入分块，也可以对预测目标进行分块，但是一直没有想到什么好的应用方法，之前尝试直接预测分块后再将分块通过线性映射映射回预测的时间序列，但效果比较一般。这里直接连线性层都省了，直接对原始序列通过块级分割映射到目标块，就得到了目标预测序列。
因为论文的review都是公开的，从openview中可以看到相关评审对该工作的一些提问，一个比较重要的是这个工作确实不能解决非线性关联的问题，另一个比较重要的是性能提高程度不大，这两个问题都比较关键，作者的回答也比较含糊，对第二点可以理解毕竟这是一个轻量级模型，只要能达到和之前的更重的模型相近的性能就足以说明模型的有效性，毕竟使用了更小的参数量和算力。
这里既然原文只构建了单通道的相关矩阵，那就可以扩展，在通道间相关性比较强的情况下，或许可以构建多通道的相关矩阵，即考虑构建原始所有通道的嵌入到目标所有通道嵌入的相关矩阵，再用类似的方式，应该会改进在多通道相关性强的数据集下的性能。
实验尝试后发现在实际测试时，在ETTm1数据集上效果一般，可能需要对超参数做细致的调整。

## A Closer Look at Transformers for Time Series Forecasting: Understanding Why They Work and Where They Struggle [@chenCloserLookTransformers]
本文主要对Transformer在时间序列预测中能够起效和无效的原因做了分析。主要解决以下四个问题
1. 为什么point-wise transformer在时间序列预测中通常竞争力较弱？
2. 为什么具有变量内注意力机制和变量间注意力机制的Transformer表现相似？
3. 为什么采用基础注意力机制的Transformer在时间序列预测中表现出色？
4. 基础Transformer架构中的哪些组件对时间序列预测的成功贡献最大？
结论：point-wise类的模型无法有效捕捉变量内部模式因此一般效果不佳。而目前常用的测评数据集的变量在很大程度上是自依赖的，变量间仅表现出较弱的互依赖性，因此得到2的原因。即使是iTransformer这种架构上显式建模变量间关系的模型，其性能也是主要来源于捕捉变量内部模式。

对问题4，作者对各个组件进行了消融实验，表 3 的结果显示，移除跳跃连接显著降低了模型在所有基准数据集上的性能，尤其是在 Electricity 数据集上（MAE 从 0.266 上升至 0.320）和 Traffic 数据集上（MAE 从 0.283 上升至 0.591）性能下降尤为明显。然而，在合成数据集上，这种性能下降变得微乎其微，同时自依赖性减弱（即自相关 γ 降低，或变量间依赖性 α 增强）。这一观察表明，跳跃连接对于捕捉变量内依赖关系至关重要，但可能限制模型捕捉变量间模式的能力。另一方面，将变量无关解码器替换为变量相关解码器对基准数据集的性能影响较小，但在自相关性较低（ γ=0.5 ）且变量间依赖性较高（ α=0.8 ）的合成数据集上提升了性能。这表明变量相关解码器增强了模型捕捉变量间交互的能力，特别是在具有强变量间依赖性的场景中。 一个更先进的解码器设计可能进一步增强在具有强变量间依赖性的数据集上的性能，这可以作为未来的考虑方向。这里的结论其实告诉我们，如果在这些数据集上设计模型，就不需要考虑设计通道独立的解码器，所有通道共用一个解码器即可。
![](https://pic1.imgdb.cn/item/68df869bc5157e1a88539967.png)
各个数据集的特性如下图，可见根据Var Corr变量间相关性可知，Traffic和Electricity两个数据集的变量间相关性更强一些，这和之前实验过程中的发现是一致的，因为那些引入了变量间关系的模型实际上在ETT数据集上的表现不如只建模变量内关系的模型，但在Traffic和Electricity这种数据集上效果就会好一些。出乎意料的是Weather数据集变量间相关性竟然也不大，作者在这里提到变量间相关性并不能完全代表变量间的依赖关系。
![](https://pic1.imgdb.cn/item/68df8660c5157e1a88539867.png)

## Time-LLM [@jinTimeLLMTimeSeries2023]
本文主要研究如何充分利用LLM已有的强大序列建模能力来建模时间序列，核心方法为将时间序列重编程为自然语言的词嵌入，重编程的方式为使用交叉注意力，在将原始的时间序列Patch并投影到d维度后，对Patch的嵌入和词嵌入进行交叉注意力，Q为Patch的嵌入，K V为词嵌入，这样最终得到的交叉注意力的输出即为符合Patch信息的词嵌入的输出，随后使用了Prompt-as-Prefix技术，该技术的含义是将数据集上下文信息，任务指令和输入统计信息如趋势和滞后等（均为文本）通过文本的Embedder嵌入后作为前缀，将刚才对Patch进行重编程后得到的嵌入拼接在前缀的后面，通过冻结的LLM后丢弃前缀部分，仅取Patch嵌入对应的部分并通过线性头映射得到最终预测结果。
![](https://pic1.imgdb.cn/item/68faef413203f7be00935f00.png)
本文的核心思路是重编程的思想，也算得上是一种迁移学习，只是如何迁移本文给出了一种很好的思路，可以使用轻量化的网络将时间序列数据映射到词嵌入空间，再结合一些元信息，无需对LLM本身做任何改动即可得到不错的预测效果。
注意文中讨论了将Patch嵌入放在前面和将文本提示等元信息的嵌入放在前面两种不同的顺序造成的影响，如果将Patch嵌入放在前面，会有以下问题:
(1) 在没有外部工具辅助的情况下，语言模型处理高精度数字的敏感度通常较低，这给准确处理长时域的实际预测任务带来了巨大挑战；
(2) 针对不同的语言模型，需要进行复杂且定制化的后处理，因为它们在不同的语料库上进行预训练，并且在精确高效地生成高精度数字时可能采用不同的分词类型。这导致预测结果以不同的自然语言格式呈现，例如用 \[‘0’, ‘.’, ‘6’, ‘1’] 和 \[‘0’, ‘.’, ‘61’] 来表示十进制数 0.61。
文中说明，将元信息的嵌入放在前面可以避免这些问题。元信息的示例如下
![](https://pic1.imgdb.cn/item/68faf4e53203f7be0093876c.png)
## RAD 
Diffusion中的t用于表示加躁的步数，这一步一般使用一个噪声嵌入来表示，这个嵌入作用于样本整体，即
但为了更精细化的控制，可以将之前直接作用于样本整体的噪声改为对样本中每个像素施加不同强度的噪声，在图像修复的任务中，可以分两阶段进行加躁，第一阶段仅对需要被预测的未知区域进行加噪，第二阶段对剩余的已知区域进行加噪，最终得到的加噪结果要和直接对样本整体进行加噪最终得到标准高斯分布相一致。训练时进行完整的加躁去噪过程，在用于根据已知图像填补未知区域时则是只使用第一阶段，给出的输入是包含已知图像区域和未知区域的图像，通过第一阶段对应的去噪过程最终得到真实的数据。


## 心电数据赛事数据
### PhysioNet/CinC Challenge 2021 Results
根据实际需求，只采用12导联中的3导联数据做后续的分类分析。
## 数据集
### ETT数据集
表示变压器
### UEA数据集
包含多个单变量分类任务数据集和多变量分类任务数据集，常用其中10个多变量分类任务数据集。

| 名称                   | 序列长度 | 类别数量 | 维度数量 | 类型      | 说明                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| -------------------- | ---- | ---- | ---- | ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Heartbeat            | 405  | 2    | 61   | 音频      | 该数据集源自 2016 年 PhysioNet/CinC 挑战赛。心音录音来自全球多位贡献者，采集于临床或非临床环境，对象包括健康受试者和病理患者。心音录音从身体不同部位采集，典型位置包括主动脉区、肺动脉区、三尖瓣区和二尖瓣区，但也可能来自九个不同位置之一。声音被分为两类：正常与异常。正常录音来自健康受试者，异常录音则来自确诊心脏病的患者。患者罹患多种疾病，但主要为心脏瓣膜缺陷和冠状动脉疾病患者。心脏瓣膜缺陷包括二尖瓣脱垂、二尖瓣反流、主动脉瓣狭窄及瓣膜手术。所有患者录音均统一标记为异常。健康受试者与病理患者均涵盖儿童和成人。每段录音均被截取为 5 秒时长。 随后，为每个实例创建了频谱图，窗口大小为 0.061 秒，重叠率为 70%。这个多变量数据集中的每个实例被安排成每个维度代表频谱图中的一个频带。正常和异常两个类别分别包含 113 和 296 个样本。                                                                                                                                                                                                                                                                                                                                                                          |
| UWaveGestureLibrary  | 315  | 8    | 3    | HAR     | 一组由加速度计生成的八种简单手势。数据包含每个动作的 X、Y、Z 坐标。每个序列长度为 315。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |
| FaceDetection        | 62   | 2    | 144  | EEG     | 该数据源自 2014 年 Kaggle 竞赛（详见链接）。研究目标是通过 MEG 数据判断受试者观看的是人脸图片还是杂乱图像，且需排除受试者个体差异的影响。本数据集仅包含竞赛训练数据，按患者划分为 10 个训练受试者（subject01 至 subject10）和 6 个测试受试者（subject11 至 subject16）。该数据不适合随机重采样，最适宜采用留一患者交叉验证法。每位患者约进行 580-590 次试验，共形成 5890 次训练试验和 3524 次测试样本。每次试验包含 1.5 秒 MEG 记录（从刺激开始前 0.5 秒启动）及对应类别标签：人脸（类别 1）或杂乱图像（类别 0）。数据经降采样至 250Hz 并施加 1Hz 高通滤波后，每个通道获得 62 个观测点。每次试验记录 306 个时间序列，对应 306 个通道各一个。                                                                                                                                                                                                                                                                                                                                                                                 |
| EthanolConcentration | 1751 | 4    | 3    | SPECTRO | 乙醇浓度数据集收录了 44 种不同真实威士忌瓶中水-乙醇溶液的原始光谱数据~\cite{large2018detecting}。乙醇浓度分别为 35%、38%、40%和 45%。苏格兰威士忌的最低法定酒精限量为 40%，许多威士忌确实保持这一酒精浓度。生产商必须确保其烈酒产品的酒精浓度与标签标注值严格吻合。该分类问题旨在测定任意瓶装样本的酒精浓度。数据经过特殊编排，每个实例由同一瓶同一批次溶液的三次重复读数构成。每种浓度（批次）制备了三份溶液，每个瓶子与批次的组合均测量三次。每次读数包含取瓶、将瓶子置于光源与光谱仪之间、保存光谱等步骤。光谱记录采用单台 StellarNet BLACKComet-SR 光谱仪的最大波长范围（226 纳米至 1101.5 纳米，采样频率 0.5 纳米），积分时间为一秒。 除了避免瓶子上的标签、压花和接缝外，并未特别尝试为每个瓶子获取最清晰的读数，也未精确复制每次重复读数时穿过瓶子的确切路径。这是为了模拟操作员未来可能对一批可疑烈酒进行大规模筛查的条件。                                                                                                                                                                                                                                                                                                         |
| Handwriting          | 152  | 26   | 3    | HAR     | 该数据集记录了受试者在智能手表上书写 26 个英文字母时的动作数据，由加州大学河滨分校创建。包含 150 个训练样本和 850 个测试样本。六个维度分别为三轴加速度计数值和三轴陀螺仪读数。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| JapaneseVowels       | 29   | 9    | 12   | AUDIO   | UCI 档案数据集。记录了 9 名日本男性发音者说出元音“a”和“e”的声音。对原始录音应用“12 阶线性预测分析”，得到 12 维时间序列，原始长度介于 7 到 29 之间。在此数据集中，实例已被填充至最大长度 29。分类任务是预测发音者。因此，每个实例是一个经过转换的话语，包含 12*29 个数值，并附有一个类别标签[1...9]。给定训练集包含每位发音者的 30 个话语，但测试集根据时间和实验可用性等外部因素具有不同的分布，每位发音者实例数在 24 到 88 之间。                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| SelfRegulationSCP1   | 896  | 2    | 6    | EEG     | 慢皮层电位自我调节。由蒂宾根大学提供的数据集。实验描述：数据集取自一名健康受试者。受试者被要求在计算机屏幕上上下移动光标，同时记录其皮层电位。在记录过程中，受试者会收到其慢皮层电位（Cz-乳突）的视觉反馈。皮层正电位导致光标在屏幕上向下移动，皮层负电位导致光标向上移动。每次试验持续 6 秒。在每次试验中，从第 0.5 秒到试验结束，通过在屏幕顶部或底部高亮显示目标来视觉呈现任务，以指示负电位或正电位。视觉反馈从第 2 秒呈现至第 5.5 秒。仅提供每次试验中这 3.5 秒的时间间隔用于训练和测试。256 Hz 的采样率和 3.5 秒的记录时长导致每次试验每个通道有 896 个样本。 试验结构概述：持续时间：6 秒，无试验间隔 任务呈现时间：0.5 秒至 6.0 秒 反馈时段：2.0 秒至 5.5 秒 数据：放大器：PsyLab EEG8 模数转换器：Computer Boards PCIM-DAS1602/16 位 幅度范围：±1000 微伏 采样率：256 次/秒 脑电数据采集位置： 通道 1：A1-Cz（10/20 系统）（A1=左乳突） 通道 2：A2-Cz 通道 3：C3 前 2 厘米 通道 4：C3 顶后 2 厘米 通道 5：C4 前 2 厘米 通道 6：C4 顶后 2 厘米 所有数值单位为微伏。 训练数据包含 268 次试验记录，来自两个不同日期并随机混合。其中 168 次试验源自第 1 天，剩余 100 次试验源自第 2 天。 数据来源于两个训练文件 Traindata_0.txt 和 Traindata_1.txt。 每个实例包含 6 个维度（上述脑电通道），长度为 896。 类别标签为阴性或阳性。 测试数据共 293 条，其标签在竞赛结束后公布。 |
| SelfRegulationSCP2   | 1152 | 2    | 7    | EEG     | 慢皮层电位的自我调节。由蒂宾根大学提供的数据集。这些数据集取自一名人工通气的 ALS 患者。受试者被要求在计算机屏幕上上下移动光标，同时记录其皮层电位。在记录过程中，受试者通过听觉和视觉反馈了解其慢皮层电位（Cz-乳突）情况。皮层正电位导致光标在屏幕上向下移动，皮层负电位则导致光标向上移动。每次试验持续 8 秒。在每次试验中，从第 0.5 秒到第 7.5 秒，屏幕上会通过顶部（负电位）或底部（正电位）的高亮目标进行视觉和听觉任务提示。此外，在第 0.5 秒时会语音提示任务方向（向上或向下）。视觉反馈从第 2 秒持续到第 6.5 秒。仅提供每次试验中这 4.5 秒的时间段用于训练和测试。256 赫兹的采样率和 4.5 秒的记录时长使得每个通道每次试验产生 1152 个样本。试验结构概述：持续时间 8 秒，无试验间隔。 任务呈现时段：0.5 秒至 7.5 秒。反馈时段：2.0 秒至 6.5 秒。脑电图数据采集位置如下：通道 1：A1-Cz（10/20 系统）（A1=左乳突）；通道 2：A2-Cz；通道 3：C3 前 2 厘米；通道 4：C3 顶后 2 厘米；通道 5：用于检测垂直眼动的 vEOG 伪迹通道；通道 6：C4 前 2 厘米；通道 7：C4 顶后 2 厘米。脑电数值未经眼电校正。训练数据包含 200 次试验，每类 100 次，均于同一天记录并随机排列。数据维度为 7，序列长度为 1152。测试数据包含 180 次试验，于训练数据之后（同一天）记录。这 180 次试验属于类别 0 或类别 1。需注意，该数据集是否包含对分类任务有用的信息尚不明确。结果观察表明并无有效信息。最佳错误率为 45.5%。                                 |
| SpokenArabicDigits   | 93   | 10   | 13   | SPEECH  | 该数据集取自 UCI 知识库，源自语音数据。数据集包含 8800 条（10 个数字×10 次重复×88 位发音人）时间序列，每条序列包含 13 个梅尔频率倒谱系数（MFCCs），采集自 44 名男性和 44 名女性阿拉伯语母语者（年龄 18-40 岁），用于表示十个阿拉伯语口语数字。数据库中每行按升序排列 13 个 MFCC 系数，以空格分隔，对应一个分析帧。13 个梅尔频率倒谱系数（MFCCs）的计算条件如下：采样率 11025Hz、16 位；应用汉明窗；滤波器预加重：1-0.97Z^(-1)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |
| PEMS-SF              | 144  | 7    | 963  | OTHER   | 数据来自加利福尼亚州交通部 PEMS 网站，涵盖 15 个月的每日记录。数据描述了旧金山湾区高速公路不同车道的占用率，数值范围在 0 到 1 之间。测量时间从 2008 年 1 月 1 日至 2009 年 3 月 30 日，每 10 分钟采样一次。我们将数据库中的每一天视为一个维度为 963（在研究期间持续正常工作的传感器数量）、长度为 6×24=144 的时间序列。数据集中移除了公共假日以及两个异常日期（2009 年 3 月 8 日和 2008 年 3 月 9 日），在这两天凌晨 2:00 至 3:00 期间所有传感器均无记录。最终数据库包含 440 条时间序列。任务是将每一天正确分类为周一至周日中的某一天，例如用{1,2,3,4,5,6,7}中的整数进行标注。 每个属性描述了在一天中特定时间戳下，由测量站记录的传感器位置占用率（介于 0 到 1 之间）的测量值。每个站点的 ID 在 stations_list 文本文件中给出。有关每个站点位置（GPS、高速公路、方向）的更多信息，请参阅 PEMS 网站。每条记录包含 963（站点）x 144（时间戳）= 138,672 个属性                                                                                                                                                                                                                                                        |

#### UEA数据集的加载（TSlib版）

### weather数据集
收集了德国的21个气象指标，如湿度和气温等，这些数据来自马克斯·普朗克生物地球化学研究所的气象站，在2020年每10分钟收集一次。

### traffic数据集
记录了由862个传感器测量的每小时道路占用率，这些传感器位于旧金山湾区的高速公路上，数据收集时间从2015年1月到2016年12月。
### exchange数据集
收集了来自8个国家从1990年到2016年的每日汇率面板数据。
### ILI数据集
记录了2002年到2021年期间美国每周患者数量和流感样疾病比例。

相关实验位于：[[在人工构造数据集上的实验]]

